{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Final Project\n",
    "# Blog Content Characterization (Morality, Emotion Analysis, Topic Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstract\n",
    "===============\n",
    "Blogs have become crucial to our daily lives, whether it be reading newsletters, and journals, documenting our stories, or following others' stories. \n",
    "Blogs are one of the important advancements of web2.0. Blog extends to other social media like Twitter and Facebook posts. <br>As important as blogs are, their content also plays a crucial role in the daily influence of their audience and writer. \n",
    "Audiences get influenced while writers become influential.<br> Characterizing blog content is analyzing and being able to label the blog by using various social metrics that are backed by a machine learning approach. With this in mind, this work will endeavor to apply various available machine learning approaches and libraries in characterizing blogs and their content helping users understand the influence of the blog or the author and attributing the written label to the blog to help users decode the underlying message of the author that the audience may not be able to infer naturally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Many audiences read blogs and news articles online, and users usually bookmark their preferred blogs and subscribe to RSS (Really Simple Syndication) feeds from these blogs. <br>\n",
    "Users have a limited understanding of the fact that they are being influenced by the author while some authors have a limited understanding of how much their influence is growing. <br>\n",
    "Usually, some of these blogs may post information that may contain information or words that may help classify them rather than rely on the tags that the author may have given the website when creating the website. <br>\n",
    "\n",
    "The topic analysis is used to figure out a text's topic structure, which is a picture of what topics are in a text and how they change over time. <br>The topic analysis consists of two main tasks: topic identification and text segmentation (based on topic changes). \n",
    "\n",
    "Emotions can be expressed verbally through emotional vocabulary or through nonverbal cues like intonation of voice, facial expressions, and gestures, all of which play an important role in human communication. <br>Most human-computer interaction (HCI) systems lack emotional intelligence and are incapable of interpreting emotions. For blog information retrieval, it is essential to characterize blog content using relevant, dependable, and distinguishing tags.\n",
    "\n",
    "Although some authors traditionally set out to influence their audience, the majority of blog authors are usually of the opinion that they are expressing their point of view and things that they are passionate about.<br> Hence, being able to run some social analysis and using machine learning to classify these blogs will help the readers immensely to understand the author while the author will understand their content and the reason why their following is either decreasing or reducing depending on the preference of the author. <br>This is why we have introduced combined social analysis as a way of characterizing the collected blog data for this study.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "To carry out this study, we will briefly describe each method and tool we will leverage on. \n",
    "First, we will collect blog data for about a two-year period by crawling blogs of interest. We will not use a keyword in collecting this data as we intend to use our results to describe or label these blogs by using results generated from morality, topic analysis, and emotion assessments. This will then allow us to use a classification model to classify these blogs.\n",
    "\n",
    "### Dataset Description\n",
    "\n",
    "The dataset to be used for this study was crawled using a crawler tool specifically focusing on indo-pacific blogs i.e blogs that discuss key issues related to the indo-pacific region, the collected blog is then stored in a CSV file and uploaded to the GitHub page link below. The repository will also house subsequent project source code implementation. \n",
    "\n",
    "https://github.com/nakinnubis/inpacblogdata\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "#### Topic Analysis\n",
    "\n",
    "We will be using Latent Semantic Analysis (LSA -NLP) for topic analysis. This approach supports singular value decomposition by keeping documents and words in a semantic space for classification hence it fits into our goal of characterizing blog post content and information.\n",
    "\n",
    "\n",
    "#### Morality Analysis\n",
    "\n",
    "For morality assessment, we will use the moral foundation theory along with a probabilistic inference to identify the changes. Using the MFT algorithm for moral quantification, this NLP approach will allow us to classify each blog post according to the appropriate moral scores.\n",
    "\n",
    "#### Emotion Assessment\n",
    "\n",
    "To predict emotions, we will be using Bidirectional LSTM with a CNN  and use Plutchikâ€™s Wheel of Emotions to represent human emotions which will form the labels for each corpus of the document. We intend to have labels like joy, anger, sadness, and fear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Discussion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install nbformat\n",
    "# Import the wordcloud library\n",
    "%pip install wordcloud\n",
    "%pip install pyldavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules\n",
    "import pandas as pd\n",
    "# import os\n",
    "\n",
    "# os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data into blogPosts\n",
    "blogPosts = pd.read_csv('Indo-pacific-blog-data.csv')\n",
    "\n",
    "# Print head\n",
    "# This shows us the content of the crawled blog data for analysis purpose\n",
    "blogPosts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columns that are not useful for this study examples of removed columns are 'categories', 'comments_url'\n",
    "blogPosts = blogPosts.drop(columns=['categories', 'comments_url'], axis=1)\n",
    "\n",
    "# Print out the first rows of blogPosts with new updated dataframe excluding 'categories', 'comments_url'\n",
    "blogPosts.head()\n",
    "blogPosts.to_csv(\"./results/lda/Indo-pacific-blog-post.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the regular expression library\n",
    "import re\n",
    "\n",
    "# Remove punctuation and unwanted dataset to allow a more clean data when we start performing LDA on the dataset\n",
    "# We used the post column for this purpose and create a new column from the dataset blog_post_processed column\n",
    "blogPosts['blog_post_processed'] = \\\n",
    "blogPosts['post'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "\n",
    "# Convert the all text to lowercase for the processed blogpost column\n",
    "blogPosts['blog_post_processed'] = \\\n",
    "blogPosts['blog_post_processed'].map(lambda x: x.lower())\n",
    "\n",
    "# Print out the head section which represents the first few columns present in the dataset\n",
    "blogPosts['blog_post_processed'].head()\n",
    "blog_post_processed_header = ['blogpost_id','title','date','blogger','tags','sentiment','location','blog_post_processed']\n",
    "blogPosts.to_csv(\"./results/lda/Indo-pacific-processed-post.csv\", columns=blog_post_processed_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Join the different processed titles together.\n",
    "long_string = ','.join(list(blogPosts['blog_post_processed'].values))\n",
    "\n",
    "# Create a WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=1000, width=800, contour_width=2, contour_color='steelblue', height=800)\n",
    "\n",
    "# Generate a word cloud\n",
    "wordcloud.generate(long_string)\n",
    "\n",
    "# Visualize the word cloud\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        # deacc=True removes punctuations\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) \n",
    "             if word not in stop_words] for doc in texts]\n",
    "\n",
    "\n",
    "data = blogPosts['blog_post_processed'].values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "# data_words\n",
    "print(data_words[:1][0][:len(data_words)-1])\n",
    "words = pd.DataFrame(data_words[:1][0][:len(data_words)-1])\n",
    "words.to_csv(\"results/lda/Indo-pacific-processed-words.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1][0][:len(corpus)-1])\n",
    "corpus_terms_m = pd.DataFrame(corpus[:1][0][:len(corpus)-1])\n",
    "corpus_terms_m.to_csv(\"results/lda/Indo-pacific-processed-corpus_terms_m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# number of topics\n",
    "num_topics = 10\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]\n",
    "doc_ld_df = pd.DataFrame(doc_lda)\n",
    "doc_ld_df.to_csv(\"results/lda/Indo-pacific-processed-doc_lda.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pickle\n",
    "import re\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "LDAvis_data_filepath = os.path.join('./results/lda/ldavis_prepared_'+str(num_topics))\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "\n",
    "pyLDAvis.save_html(LDAvis_prepared, './results/lda/ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Morality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_input = pd.read_csv('data/Indo-pacific-blog-data_morality.csv', header=None)\n",
    "template_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emfdscore.scoring import score_docs \n",
    "\n",
    "num_docs = len(template_input)\n",
    "\n",
    "DICT_TYPE = 'emfd'\n",
    "PROB_MAP = 'all'\n",
    "SCORE_METHOD = 'bow'\n",
    "OUT_METRICS = 'vice-virtue'\n",
    "OUT_CSV_PATH = 'all-vv.csv'\n",
    "\n",
    "df = score_docs(template_input,DICT_TYPE,PROB_MAP,SCORE_METHOD,OUT_METRICS,num_docs)\n",
    "df.to_csv(OUT_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect output \n",
    "all_vv = pd.read_csv('all-vv.csv')\n",
    "all_vv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emfdscore.scoring import score_docs \n",
    "\n",
    "num_docs = len(template_input)\n",
    "\n",
    "DICT_TYPE = 'emfd'\n",
    "PROB_MAP = 'single'\n",
    "SCORE_METHOD = 'bow'\n",
    "OUT_METRICS = 'vice-virtue'\n",
    "OUT_CSV_PATH = 'single-vv.csv'\n",
    "\n",
    "df = score_docs(template_input,DICT_TYPE,PROB_MAP,SCORE_METHOD,OUT_METRICS,num_docs)\n",
    "df.to_csv(OUT_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect output \n",
    "single_vv = pd.read_csv('single-vv.csv')\n",
    "single_vv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emfdscore.scoring import score_docs \n",
    "\n",
    "num_docs = len(template_input)\n",
    "\n",
    "DICT_TYPE = 'mfd2'\n",
    "PROB_MAP = ''\n",
    "SCORE_METHOD = 'bow'\n",
    "OUT_METRICS = ''\n",
    "OUT_CSV_PATH = 'mfd2.csv'\n",
    "\n",
    "df = score_docs(template_input,DICT_TYPE,PROB_MAP,SCORE_METHOD,OUT_METRICS,num_docs)\n",
    "df.to_csv(OUT_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect output \n",
    "mfd2 = pd.read_csv('mfd2.csv')\n",
    "mfd2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emfdscore.scoring import score_docs \n",
    "\n",
    "num_docs = len(template_input)\n",
    "\n",
    "DICT_TYPE = 'mfd'\n",
    "PROB_MAP = ''\n",
    "SCORE_METHOD = 'bow'\n",
    "OUT_METRICS = ''\n",
    "OUT_CSV_PATH = 'mfd.csv'\n",
    "\n",
    "df = score_docs(template_input,DICT_TYPE,PROB_MAP,SCORE_METHOD,OUT_METRICS,num_docs)\n",
    "df.to_csv(OUT_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>care.virtue</th>\n",
       "      <th>fairness.virtue</th>\n",
       "      <th>loyalty.virtue</th>\n",
       "      <th>authority.virtue</th>\n",
       "      <th>sanctity.virtue</th>\n",
       "      <th>care.vice</th>\n",
       "      <th>fairness.vice</th>\n",
       "      <th>loyalty.vice</th>\n",
       "      <th>authority.vice</th>\n",
       "      <th>sanctity.vice</th>\n",
       "      <th>moral</th>\n",
       "      <th>moral_nonmoral_ratio</th>\n",
       "      <th>f_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.045213</td>\n",
       "      <td>0.010150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.041725</td>\n",
       "      <td>0.008840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>0.025926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.046832</td>\n",
       "      <td>0.009419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.094148</td>\n",
       "      <td>0.029089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   care.virtue  fairness.virtue  loyalty.virtue  authority.virtue  \\\n",
       "0     0.058824         0.117647        0.117647          0.117647   \n",
       "1     0.200000         0.000000        0.133333          0.200000   \n",
       "2     0.333333         0.000000        0.000000          0.333333   \n",
       "3     0.117647         0.000000        0.000000          0.058824   \n",
       "4     0.027027         0.027027        0.162162          0.027027   \n",
       "\n",
       "   sanctity.virtue  care.vice  fairness.vice  loyalty.vice  authority.vice  \\\n",
       "0         0.058824   0.352941            0.0      0.058824        0.000000   \n",
       "1         0.066667   0.233333            0.0      0.100000        0.000000   \n",
       "2         0.000000   0.333333            0.0      0.000000        0.000000   \n",
       "3         0.117647   0.294118            0.0      0.117647        0.176471   \n",
       "4         0.000000   0.540541            0.0      0.189189        0.000000   \n",
       "\n",
       "   sanctity.vice     moral  moral_nonmoral_ratio     f_var  \n",
       "0       0.058824  0.058824              0.045213  0.010150  \n",
       "1       0.000000  0.166667              0.041725  0.008840  \n",
       "2       0.000000  0.000000              0.029703  0.025926  \n",
       "3       0.000000  0.117647              0.046832  0.009419  \n",
       "4       0.000000  0.027027              0.094148  0.029089  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect output \n",
    "mfd = pd.read_csv('mfd.csv')\n",
    "mfd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_morality_data(rowData):\n",
    "    vice = {\n",
    "        'care': rowData[\"care.vice\"],\n",
    "        'fairnaess': rowData[\"fairness.vice\"],\n",
    "        'loyalty':rowData[\"loyalty.vice\"],\n",
    "        'authority':rowData[\"authority.vice\"],\n",
    "        'sanctity': rowData[\"sanctity.vice\"]\n",
    "    }\n",
    "    virtue = {\n",
    "        'care': rowData[\"care.virtue\"],\n",
    "        'fairnaess': rowData[\"fairness.virtue\"],\n",
    "        'loyalty':rowData[\"loyalty.virtue\"],\n",
    "        'authority':rowData[\"authority.virtue\"],\n",
    "        'sanctity': rowData[\"sanctity.virtue\"]\n",
    "    }\n",
    "    return max(vice, key=vice.get), max(virtue, key=virtue.get)\n",
    "\n",
    "def vice_label(rowData):\n",
    "   (vice,virtue) = label_morality_data(rowData=rowData)\n",
    "   return vice\n",
    "\n",
    "def virtue_label(rowData):\n",
    "   (vice,virtue) = label_morality_data(rowData=rowData)\n",
    "   return virtue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# care.vice\tfairness.vice\tloyalty.vice\tauthority.vice\tsanctity.vice\n",
    "mfd['vice'] = mfd.apply(lambda rowData: vice_label(rowData), axis=1)\n",
    "mfd['virtue'] = mfd.apply(lambda rowData: virtue_label(rowData), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>care.virtue</th>\n",
       "      <th>fairness.virtue</th>\n",
       "      <th>loyalty.virtue</th>\n",
       "      <th>authority.virtue</th>\n",
       "      <th>sanctity.virtue</th>\n",
       "      <th>care.vice</th>\n",
       "      <th>fairness.vice</th>\n",
       "      <th>loyalty.vice</th>\n",
       "      <th>authority.vice</th>\n",
       "      <th>sanctity.vice</th>\n",
       "      <th>moral</th>\n",
       "      <th>moral_nonmoral_ratio</th>\n",
       "      <th>f_var</th>\n",
       "      <th>vice</th>\n",
       "      <th>virtue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.045213</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>care</td>\n",
       "      <td>fairnaess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.041725</td>\n",
       "      <td>0.008840</td>\n",
       "      <td>care</td>\n",
       "      <td>care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>0.025926</td>\n",
       "      <td>care</td>\n",
       "      <td>care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.046832</td>\n",
       "      <td>0.009419</td>\n",
       "      <td>care</td>\n",
       "      <td>care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.094148</td>\n",
       "      <td>0.029089</td>\n",
       "      <td>care</td>\n",
       "      <td>loyalty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   care.virtue  fairness.virtue  loyalty.virtue  authority.virtue  \\\n",
       "0     0.058824         0.117647        0.117647          0.117647   \n",
       "1     0.200000         0.000000        0.133333          0.200000   \n",
       "2     0.333333         0.000000        0.000000          0.333333   \n",
       "3     0.117647         0.000000        0.000000          0.058824   \n",
       "4     0.027027         0.027027        0.162162          0.027027   \n",
       "\n",
       "   sanctity.virtue  care.vice  fairness.vice  loyalty.vice  authority.vice  \\\n",
       "0         0.058824   0.352941            0.0      0.058824        0.000000   \n",
       "1         0.066667   0.233333            0.0      0.100000        0.000000   \n",
       "2         0.000000   0.333333            0.0      0.000000        0.000000   \n",
       "3         0.117647   0.294118            0.0      0.117647        0.176471   \n",
       "4         0.000000   0.540541            0.0      0.189189        0.000000   \n",
       "\n",
       "   sanctity.vice     moral  moral_nonmoral_ratio     f_var  vice     virtue  \n",
       "0       0.058824  0.058824              0.045213  0.010150  care  fairnaess  \n",
       "1       0.000000  0.166667              0.041725  0.008840  care       care  \n",
       "2       0.000000  0.000000              0.029703  0.025926  care       care  \n",
       "3       0.000000  0.117647              0.046832  0.009419  care       care  \n",
       "4       0.000000  0.027027              0.094148  0.029089  care    loyalty  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_moraltiy_score(rowData):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emotion Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "%pip install keras\n",
    "%pip3 install torch torchvision torchaudio\n",
    "\n",
    "%pip install git+https://github.com/UBC-NLP/EmoNet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from emonet import EmoNet\n",
    "import pandas as pd \n",
    "em = EmoNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict text in a tsv file line by line\n",
    "blogPosts = pd.read_csv('results/lda/Indo-pacific-processed-post.csv')\n",
    "processedBlogPost =  blogPosts.blog_post_processed\n",
    "processedBlogPost\n",
    "def predict_labels(post):\n",
    "    predictions = em.predict(post)\n",
    "    predictions = predictions[0]\n",
    "    (label, score) = predictions \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_scores(post):\n",
    "    predictions = em.predict(post)\n",
    "    predictions = predictions[0]\n",
    "    (label, score) = predictions \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blogPosts['emotion'] = blogPosts.apply(lambda row: predict_labels(row['blog_post_processed']), axis=1)\n",
    "blogPosts['emotions_score'] = blogPosts.apply(lambda row: predict_scores(row['blog_post_processed']), axis=1)\n",
    "blogPosts.head()\n",
    "\n",
    "blogPosts.to_csv('results/emos/Indo-pacific-processed-post-emotions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blog Text-Classification using Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sqlite3 import Error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sqlite3\n",
    "import pickle\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/Indo-pacific-processed-post-emotions.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns=['Unnamed: 0.1', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.groupby('emotion').emotions_score.plot.bar(ylim=0)\n",
    "plt.figure(figsize=(10, 10))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stemmer = PorterStemmer()\n",
    "words = stopwords.words(\"english\")\n",
    "dataset['cleaned'] = dataset['blog_post_processed'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df= 3, stop_words=\"english\", sublinear_tf=True, norm='l2', ngram_range=(1, 2))\n",
    "final_features = vectorizer.fit_transform(dataset['cleaned']).toarray()\n",
    "final_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "X = dataset['cleaned']\n",
    "Y = dataset['emotion']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "pipeline = Pipeline([('vect', vectorizer),\n",
    "                     ('chi',  SelectKBest(chi2, k=1200)),\n",
    "                     ('clf', LogisticRegression(random_state=0))])\n",
    "\n",
    "model = pipeline.fit(X_train, y_train)\n",
    "with open('LogisticRegression.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "ytest = np.array(y_test)\n",
    "\n",
    "# confusion matrix and classification report(precision, recall, F1-score)\n",
    "print(classification_report(ytest, model.predict(X_test)))\n",
    "print(confusion_matrix(ytest, model.predict(X_test)))\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "plot_confusion_matrix(model, X_test, ytest,ax=ax)  \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
